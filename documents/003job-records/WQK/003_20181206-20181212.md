**工作记录**
<br>

**2018.12.06 - 2018.12.12**

---
**1、完成爬虫数据采集**
- 使用通用爬虫框架crawlspider，设置rule属性即可自动完成筛选爬取所需数据
- 爬取地址为:[https://sdk.cn](https://sdk.cn)
- 采用存储过程，处理爬取数据，每次获取的数据为tool的基本属性与一个tags数组，取得数据后，不重复地插入一条tool，多条tag，随后再更新tag_tool表，不重复地插入并将tool与tag关联

**2、写了博客**
- 在eclipse中搭建ssm框架并完成对数据库的查询操作，地址[ssm整合配置博客](https://www.cnblogs.com/wangqinkuan/p/10089643.html)

